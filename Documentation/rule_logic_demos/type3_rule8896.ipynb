{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd77f1c",
   "metadata": {},
   "source": [
    "# Code logic of Rule 8896\n",
    "\n",
    "We wouldn't want you to simply fill in the gaps and replace variable names when you do these rules. It is important to us that you learn the concepts behind the rules too, as you go. \n",
    "\n",
    "This file demonstrates the code logic of Rule 8896, a type 3 rule. Type 3 rules are those that define scenarios that should not occur within a group. So these values might be correct on their own but if something else happens in the group, then that same value could flag the error. \n",
    "\n",
    "In this case, the rule says that \"Within one CINdetails group, there must not be more than one Assessments group that has no AssessmentAuthorisationDate (N00160) recorded\". \n",
    "\n",
    "So if an AssessmentAuthorisationDate is missing (equal to pd.NA), this rule won't flag it just because of that. What this rule will do is check if there is another AssessmentAuthorisationDate that is missing in the group. If there is, then all the positions where AssessmentAuthorisationDate is missing will be flagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "057af961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3cc253",
   "metadata": {},
   "source": [
    "The CIN validator tool contains a number of background checks and guidelines on how things should be done. As helpful as this is, it might not allow you to experiment much or run your code on the fly. So sometimes I get the data out into a clean file and write my python logic against it.\n",
    "\n",
    "Create some data and take note of the positions that you expect to be flagged.\n",
    "\n",
    "You would notice that you now need to put the column names in strings as standard Python practice requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6561070c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LAchildID CINdetailsID AssessmentAuthorisationDate\n",
      "0    child1       cinID1                         NaT\n",
      "1    child1       cinID1                         NaT\n",
      "2    child1       cinID2                         NaT\n",
      "3    child2       cinID1                  2021-05-26\n",
      "4    child2       cinID2                         NaT\n",
      "5    child2       cinID2                         NaT\n"
     ]
    }
   ],
   "source": [
    "sample_assessments = pd.DataFrame(\n",
    "    [   #child1\n",
    "        {   # fail\n",
    "            \"LAchildID\": \"child1\",\n",
    "            \"CINdetailsID\": \"cinID1\",\n",
    "            \"AssessmentAuthorisationDate\": pd.NA, # 0 first nan date in group\n",
    "        },\n",
    "        {   # fail\n",
    "            \"LAchildID\": \"child1\",\n",
    "            \"CINdetailsID\": \"cinID1\",\n",
    "            \"AssessmentAuthorisationDate\": pd.NA, # 1 second nan date in group\n",
    "        },\n",
    "        {   # won't be flagged because there is not more than one nan authorisation date in this group.\n",
    "            \"LAchildID\": \"child1\",\n",
    "            \"CINdetailsID\": \"cinID2\",\n",
    "            \"AssessmentAuthorisationDate\": pd.NA, # 2\n",
    "        }, \n",
    "        # child2 \n",
    "        {\n",
    "            \"LAchildID\": \"child2\",\n",
    "            \"CINdetailsID\": \"cinID1\", \n",
    "            \"AssessmentAuthorisationDate\": \"26/05/2021\", # 3 ignored. not nan\n",
    "        },\n",
    "        {   # fail\n",
    "            \"LAchildID\": \"child2\",\n",
    "            \"CINdetailsID\": \"cinID2\",\n",
    "            \"AssessmentAuthorisationDate\": pd.NA, # 4 first nan date in group\n",
    "        },  \n",
    "        {   # fail\n",
    "            \"LAchildID\": \"child2\",\n",
    "            \"CINdetailsID\": \"cinID2\",\n",
    "            \"AssessmentAuthorisationDate\": pd.NA, # 5 second nan date in group\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.\n",
    "sample_assessments[\"AssessmentAuthorisationDate\"] = pd.to_datetime(\n",
    "    sample_assessments[\"AssessmentAuthorisationDate\"], format=\"%d/%m/%Y\", errors=\"coerce\"\n",
    ")\n",
    "\n",
    "\n",
    "# See what your data looks like\n",
    "print(sample_assessments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa82c6",
   "metadata": {},
   "source": [
    "When you start, it is wise to ask yourself the question \"How do I get all the conditions that fail into one place?\".\n",
    "In this case, our first step is to get together all the conditions that could fail. That is, the locations where AssessmentAuthorisationDate is missing. Later on, we can proceed to check how many exist per group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d680fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ROW_ID LAchildID CINdetailsID AssessmentAuthorisationDate\n",
      "0       0    child1       cinID1                         NaT\n",
      "1       1    child1       cinID1                         NaT\n",
      "2       2    child1       cinID2                         NaT\n",
      "4       4    child2       cinID2                         NaT\n",
      "5       5    child2       cinID2                         NaT\n"
     ]
    }
   ],
   "source": [
    "df = sample_assessments\n",
    "df.index.name = \"ROW_ID\"\n",
    "df.reset_index(inplace=True)\n",
    "df2 = df[df[\"AssessmentAuthorisationDate\"].isna()]\n",
    "\n",
    "# See what the data looks like now\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e3e3ba",
   "metadata": {},
   "source": [
    "Generally, we would groupby the columns that define our group and count the number of items in each column. However, the count method ignores NaNs and in this case that it what we want to count. So since we have filtered only the NaN values, we can replace then with a value that can be counted. I chose to use the integer 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04972883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[:,\"AssessmentAuthorisationDate\"].fillna(1, inplace=True)\n",
    "\n",
    "# This line was added to take care of a warning being raised here. You can ignore it in other rules.\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d71f216",
   "metadata": {},
   "source": [
    "Now we can count.\n",
    "We need to groupby LAchildID and CINdetailsID because eventhough we are concerned with CINdetails groups, CINdetails groups are subgroups of each child. For example, two unique children can each contain a CINdetails group whose ID is \"abc\" within them. If we do not group by child first, our code will interpret the groups from these separate children as if they were the same because LAchildID has not been included to distinguish them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3986340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAchildID  CINdetailsID\n",
      "child1     cinID1          2\n",
      "           cinID2          1\n",
      "child2     cinID2          2\n",
      "Name: AssessmentAuthorisationDate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count how many occurences of missing \"AssessmentAuthorisationDate\" per CINdetails group in each child.\n",
    "group_result = df2.groupby([\"LAchildID\", \"CINdetailsID\"])[\"AssessmentAuthorisationDate\"].count()\n",
    "\n",
    "print(group_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1f6e93",
   "metadata": {},
   "source": [
    "The line below does the same thing as the line above. However, it shows you why we need to reset_index after doing the groupby. This is because the columns that we groupedby become the index and we have to push them back into column form. Also, you would notice that our count result is now assigned to the column we put in the square bracket of the groupby statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1392c96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LAchildID CINdetailsID  AssessmentAuthorisationDate\n",
      "0    child1       cinID1                            2\n",
      "1    child1       cinID2                            1\n",
      "2    child2       cinID2                            2\n"
     ]
    }
   ],
   "source": [
    "df2 = df2.groupby([\"LAchildID\", \"CINdetailsID\"])[\"AssessmentAuthorisationDate\"].count().reset_index()\n",
    "\n",
    "# See what the data looks like now\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e562da78",
   "metadata": {},
   "source": [
    "We get the count result by selecting the column we put in the square bracket of the groupby statement. The failing positions are only those in which there was more than one occurence of AssessmentAuthorisationDate as a missing value within the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a21d629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LAchildID CINdetailsID  AssessmentAuthorisationDate\n",
      "0    child1       cinID1                            2\n",
      "2    child2       cinID2                            2\n"
     ]
    }
   ],
   "source": [
    "# filter out the instances where \"AssessmentAuthorisationDate\" is missing more than once in a CINdetails group.\n",
    "df2 = df2[df2[\"AssessmentAuthorisationDate\"]>1]\n",
    "\n",
    "# See what the data looks like now\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf25d6c4",
   "metadata": {},
   "source": [
    "In type3 rules, a group is our unit of testing. So the column relationship that defines the group also defines the error IDs. That is, in the end the locations that fail per group should be linked to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6da226",
   "metadata": {},
   "source": [
    "We start by generating the IDs of all the failing positions which we have identified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3e848a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ROW_ID LAchildID CINdetailsID AssessmentAuthorisationDate          ERROR_ID\n",
      "0       0    child1       cinID1                         NaT  (child1, cinID1)\n",
      "1       1    child1       cinID1                         NaT  (child1, cinID1)\n",
      "2       2    child1       cinID2                         NaT  (child1, cinID2)\n",
      "3       3    child2       cinID1                  2021-05-26  (child2, cinID1)\n",
      "4       4    child2       cinID2                         NaT  (child2, cinID2)\n",
      "5       5    child2       cinID2                         NaT  (child2, cinID2)\n"
     ]
    }
   ],
   "source": [
    "issue_ids = tuple(\n",
    "    zip(df2[\"LAchildID\"], df2[\"CINdetailsID\"],)\n",
    ")\n",
    "df[\"ERROR_ID\"] = tuple(\n",
    "    zip(df[\"LAchildID\"], df[\"CINdetailsID\"],)\n",
    ")\n",
    "\n",
    "# See what the data looks like now, including ERROR_ID that has been created.\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb6efda",
   "metadata": {},
   "source": [
    "Then we go to the initial dataset, generate an ID column using that same column combination and select the rows where the ID values appear among the IDs of the failing locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9282e369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ROW_ID LAchildID CINdetailsID AssessmentAuthorisationDate          ERROR_ID\n",
      "0       0    child1       cinID1                         NaT  (child1, cinID1)\n",
      "1       1    child1       cinID1                         NaT  (child1, cinID1)\n",
      "4       4    child2       cinID2                         NaT  (child2, cinID2)\n",
      "5       5    child2       cinID2                         NaT  (child2, cinID2)\n"
     ]
    }
   ],
   "source": [
    "df_issues = df[df.ERROR_ID.isin(issue_ids)]\n",
    "\n",
    "# See what the data looks like now\n",
    "print(df_issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b6eeeb",
   "metadata": {},
   "source": [
    "In real life, this df_issues will contain all the other columns that came with the table. That data is heavy to move around so we only select the columns which we need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0017d193",
   "metadata": {},
   "source": [
    "We would like to know all the rows that failed because of the same reason. That is, lets group together all the ROW_IDs that have the same ERROR_ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5614e6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR_ID\n",
      "(child1, cinID1)    [0, 1]\n",
      "(child2, cinID2)    [4, 5]\n",
      "Name: ROW_ID, dtype: object\n"
     ]
    }
   ],
   "source": [
    "group_result = df_issues.groupby(\"ERROR_ID\")[\"ROW_ID\"].apply(list)\n",
    "\n",
    "# See what the data looks like now\n",
    "print(group_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e684709f",
   "metadata": {},
   "source": [
    "The line below does the same thing as the code above, then it shows you why we need to reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a895898c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ERROR_ID  ROW_ID\n",
      "0  (child1, cinID1)  [0, 1]\n",
      "1  (child2, cinID2)  [4, 5]\n"
     ]
    }
   ],
   "source": [
    "df_issues = df_issues.groupby(\"ERROR_ID\")[\"ROW_ID\"].apply(list).reset_index()\n",
    "\n",
    "# See what the data looks like now\n",
    "print(df_issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a98ad88",
   "metadata": {},
   "source": [
    "Now, we can push this to the issue location accumulator that prepares the data which will be sent to the frontend."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
