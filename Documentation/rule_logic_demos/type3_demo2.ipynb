{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e47f031c",
   "metadata": {},
   "source": [
    "This notebook uses demo data to explain a concept that you will come across often in the type3 rules. It will guide you through rules that sound like \"within a CINdetails group, no startDate should be between the start and end dates of any other group. if the end date is missing, replace the end date with reference date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d6a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55157c55",
   "metadata": {},
   "source": [
    "Let us consider sample data and shown below, and seek to implement this sample rule:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095f30fb",
   "metadata": {},
   "source": [
    "## In every group, flag column B values that exist within the intervals of any other colA-colB combinations in that group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ba71d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id   a  b\n",
      "0  id1   1  2\n",
      "1  id1   3  4\n",
      "2  id1  13  9\n",
      "3  id2   5  7\n",
      "4  id2   6  8\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([\n",
    "    {\"id\":\"id1\", \"a\": 1, \"b\": 2}, #0\n",
    "    {\"id\":\"id1\", \"a\": 3, \"b\": 4}, #1\n",
    "    {\"id\":\"id1\", \"a\": 13, \"b\": 9}, #2\n",
    "    \n",
    "    {\"id\":\"id2\", \"a\": 5, \"b\": 7}, #3 fail . exists between 6 and 8.\n",
    "    {\"id\":\"id2\", \"a\": 6, \"b\": 8}, #4\n",
    "])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5939cf",
   "metadata": {},
   "source": [
    "Preserving the initial index positions enables us to ensure that a row is not compared to itself. This is because, each value will exists in its own interval and hence wrongly flag the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c061efc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ROW_ID   id   a  b\n",
      "0       0  id1   1  2\n",
      "1       1  id1   3  4\n",
      "2       2  id1  13  9\n",
      "3       3  id2   5  7\n",
      "4       4  id2   6  8\n"
     ]
    }
   ],
   "source": [
    "df.index.name = \"ROW_ID\"\n",
    "df.reset_index(inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5655c17d",
   "metadata": {},
   "source": [
    "To get all the possible combinations of the values with themselves, we merge the dataframe with itself on the columns that define what a \"group\" means in our case. \n",
    "If the group needed in your rule is a subgroup e.g CPP, then you'll have to merge on all the parent groups too. That is, LAchildID, CINdetailsID and CPPID will have to be included to define a CPP group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0362e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ROW_ID   id  b  ROW_ID_check   a  b_check\n",
      "0        0  id1  2             0   1        2\n",
      "1        0  id1  2             1   3        4\n",
      "2        0  id1  2             2  13        9\n",
      "3        1  id1  4             0   1        2\n",
      "4        1  id1  4             1   3        4\n",
      "5        1  id1  4             2  13        9\n",
      "6        2  id1  9             0   1        2\n",
      "7        2  id1  9             1   3        4\n",
      "8        2  id1  9             2  13        9\n",
      "9        3  id2  7             3   5        7\n",
      "10       3  id2  7             4   6        8\n",
      "11       4  id2  8             3   5        7\n",
      "12       4  id2  8             4   6        8\n"
     ]
    }
   ],
   "source": [
    "df_check = df.reset_index()[[\"ROW_ID\",\"id\",\"b\"]].merge(df.reset_index()[[\"ROW_ID\",\"id\",\"a\", \"b\"]], on=[\"id\"], suffixes=[\"\", \"_check\"])\n",
    "\n",
    "# see what your data looks like now\n",
    "print(df_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ae96a",
   "metadata": {},
   "source": [
    "The merge result shows that suffixes are only applied to the common columns between the merge tables, so column a is unaffected. We have applied an empty string suffix (nothing changes) to the left hand side (b) and a \"_check\" suffix to the right hand side(b_check).\n",
    "\n",
    "We prevent positions from being compared to each other by removing the rows where the initial index values (ROW_IDs), of the the merged tables, are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "301a2052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ROW_ID   id  b  ROW_ID_check   a  b_check\n",
      "1        0  id1  2             1   3        4\n",
      "2        0  id1  2             2  13        9\n",
      "3        1  id1  4             0   1        2\n",
      "5        1  id1  4             2  13        9\n",
      "6        2  id1  9             0   1        2\n",
      "7        2  id1  9             1   3        4\n",
      "10       3  id2  7             4   6        8\n",
      "11       4  id2  8             3   5        7\n"
     ]
    }
   ],
   "source": [
    "df_check = df_check[~(df_check[\"ROW_ID\"]==df_check[\"ROW_ID_check\"])]\n",
    "print(df_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c6f527",
   "metadata": {},
   "source": [
    "The idea is to filter out df_check until all it has are the failing positions. \n",
    "Since we have all the possible combinations for column a and column b for every column b value in a group, we can now check if column b's value exists in the columna-columnb interval of the other combinations in its group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c54c4841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ROW_ID   id  b  ROW_ID_check  a  b_check\n",
      "10       3  id2  7             4  6        8\n"
     ]
    }
   ],
   "source": [
    "df_check = df_check[(df_check[\"b\"]>=df_check[\"a\"]) & (df_check[\"b\"]<=df_check[\"b_check\"]) ]\n",
    "print(df_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e268ac13",
   "metadata": {},
   "source": [
    "We can then proceed to create ERROR_IDs for the failing locations and then map these to the original dataframe. Your ERROR_ID should contain all the columns that define a group ( from parent group to subgroup, in that order) and the base column being compared (column b in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "492a59ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('id2', 7),)\n"
     ]
    }
   ],
   "source": [
    "error_ids = tuple(\n",
    "    zip(\n",
    "        df_check[\"id\"], df_check[\"b\"]\n",
    "    )\n",
    ")\n",
    "print(error_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1ec5fc",
   "metadata": {},
   "source": [
    "We use the exact combination of columns in error_ids to create an ERROR_ID column in our original dataframe, df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2da43e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ROW_ID   id   a  b  ERROR_ID\n",
      "0       0  id1   1  2  (id1, 2)\n",
      "1       1  id1   3  4  (id1, 4)\n",
      "2       2  id1  13  9  (id1, 9)\n",
      "3       3  id2   5  7  (id2, 7)\n",
      "4       4  id2   6  8  (id2, 8)\n"
     ]
    }
   ],
   "source": [
    "# back to original dataframe\n",
    "df[\"ERROR_ID\"] = tuple(\n",
    "    zip(\n",
    "        df[\"id\"], df[\"b\"]\n",
    "    )\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ef5e06",
   "metadata": {},
   "source": [
    "We select out all the rows of the original dataframe whose ERROR_IDs exist in the sequence of failing positions (error_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7b83238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ROW_ID   id  a  b  ERROR_ID\n",
      "3       3  id2  5  7  (id2, 7)\n"
     ]
    }
   ],
   "source": [
    "df_issues = df[df[\"ERROR_ID\"].isin(error_ids)]\n",
    "print(df_issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3260288",
   "metadata": {},
   "source": [
    "Lastly, all the index positions that have the same failing ID are grouped together so that they can be pushed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab88cb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR_ID\n",
       "(id2, 7)    [3]\n",
       "Name: ROW_ID, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_issues.groupby([\"ERROR_ID\"])[\"ROW_ID\"].apply(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a4c56",
   "metadata": {},
   "source": [
    "## Alternatively, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "736a1847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ROW_ID   id  b  ROW_ID_check  a  b_check  ERROR_ID\n",
      "10       3  id2  7             4  6        8  (id2, 7)\n"
     ]
    }
   ],
   "source": [
    "# alternatively, you could proceed from df_check directly to df_issues.\n",
    "\n",
    "df_check[\"ERROR_ID\"] = tuple(\n",
    "    zip(\n",
    "        df_check[\"id\"], df_check[\"b\"]\n",
    "    )\n",
    " )\n",
    "print(df_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d09d19",
   "metadata": {},
   "source": [
    "This method now allows us to link up the rows that failed (i.e column b, row 3) to the locations that caused the failure (column a and column b, row 4).\n",
    "\n",
    "Side note: the values 3 and 4 come from the values of ROW_ID and ROW_ID check in the failing data (df_check), respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5008609d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR_ID\n",
      "(id2, 7)    [3]\n",
      "Name: ROW_ID, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_issues = df_check.groupby([\"ERROR_ID\"])[\"ROW_ID\"].apply(list)\n",
    "print(df_issues)\n",
    "# push_type3(table=TableName, columns=[\"a\"], row_df=df_issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8290e656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR_ID\n",
      "(id2, 7)    [4]\n",
      "Name: ROW_ID_check, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_issues_check = df_check.groupby([\"ERROR_ID\"])[\"ROW_ID_check\"].apply(list)\n",
    "print(df_issues_check)\n",
    "# push_type3(table=TableName, columns[\"a\", \"b\"], row_df = df_issues_check)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
